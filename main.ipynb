{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa67fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "from osgeo import ogr  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tools.deeplab import DeepLabV3PlusMobileNetV3\n",
    "from tools.unet import UNet\n",
    "from tools.utils import merge_multiband_windowss, metrics\n",
    "from tools.object_extractor import multigeojson_to_multichannel_mask, update_metadata_only\n",
    "from tools.utils import plot_loss, optimizer_to\n",
    "from tools.segformerB0 import SegFormerB0_12Channel\n",
    "from tools.losses import FocalDiceLossBinary, AsymmetricLossOptimized\n",
    "from torch.optim.swa_utils import get_ema_multi_avg_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83843c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = \".\\\\dataset\\\\train\"\n",
    "obj_path = \".\\\\objects1.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ff3c4",
   "metadata": {},
   "source": [
    "# Генерация или чтение объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847a044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_new = True\n",
    "from tools.data_extractor import get_json\n",
    "from tools.traintest_splitter import create_train_test\n",
    "\n",
    "train_dataset, test_dataset = None, None\n",
    "\n",
    "if generate_new:\n",
    "    train_dataset, test_dataset, _, _, _, _ = create_train_test(main_path, seed=83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4c0710-2adc-4f10-b33b-211769d10f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.data_extractor import get_json\n",
    "from tools.test_splitter import create_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4ef7e0-e9e7-44b3-8f4a-52f6f0103af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model = DeepLabV3PlusMobileNetV3(num_classes=1, pretrained_backbone_path='./mobilenet_v3_small-047dcff4.pth')\n",
    "#CLASS_WEIGHTS = [4.0, 1.0, 2.0, 2.0,1.0, 2.0, 0.5,5.0,1.0,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36c579f2-59d7-4b69-b473-61b4a0c2b49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SegFormerB0_12Channel(num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bbdb2a-6166-48c7-b29d-f1ed5fcdd71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\conda\\envs\\DataScience\\Lib\\site-packages\\PIL\\Image.py:3452: DecompressionBombWarning: Image size (158961250 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.uint8(252)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open('./dataset/train/002_ДЕМИДОВКА_FINAL/02_Демидовка_Li_карты/01_Демидовка_Lidar_c.tif')\n",
    "pixels = np.array(img)\n",
    "max_value = pixels.max()\n",
    "max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09dedaf",
   "metadata": {},
   "source": [
    "## Выделение окон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5168b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box, mapping, Polygon, MultiPolygon\n",
    "import json\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "data_iter = iter(dataloader)\n",
    "tile_size=2048\n",
    "windows = []\n",
    "shapes = []\n",
    "photo_counter = 0\n",
    "for epoch in range(len(dataloader)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    single_image_batch = next(data_iter)\n",
    "    images = single_image_batch\n",
    "    print(f\"Количество обработанных изображений {photo_counter}\")\n",
    "    photo_counter += 1\n",
    "    yest_curgani = False\n",
    "    for batches in range(len(images[\"batches\"])):\n",
    "        res = images[\"batches\"][batches]\n",
    "        update_metadata_only(res[0][0], res[0][0], int(images[\"UTM\"][0]))\n",
    "        with rasterio.open(res[0][0]) as src:\n",
    "            tile_id = 0\n",
    "            stride = tile_size\n",
    "            x_range = range(0, src.width + tile_size, stride)\n",
    "            y_range = range(0, src.height + tile_size, stride)\n",
    "            #print(x_range, y_range)\n",
    "            for y in tqdm(y_range):\n",
    "                for x in x_range:\n",
    "                    window_bounds = (x, y, x+ tile_size, y + tile_size)\n",
    "                    y_end = min(window_bounds[3], int(src.height))\n",
    "                    x_end = min(window_bounds[2],  int(src.width))\n",
    "                \n",
    "                    # проверить если пересекаются для каждого полигона в файлах разметки\n",
    "                    left, top = rasterio.transform.xy(src.transform, y, x)\n",
    "                    right, bottom = rasterio.transform.xy(src.transform, y + tile_size, x + tile_size)\n",
    "                    window_bbox = box(left, bottom, right, top)\n",
    "                    crs = src.crs\n",
    "                    # окно в системе изображения\n",
    "                    # теперь фор по файлам и в них по полигонам\n",
    "                    for path_raw in images[\"vector_mask\"]:\n",
    "                        path = path_raw[0]\n",
    "                        fname_lower = os.path.basename(path).lower()\n",
    "                        cur_class = None\n",
    "                        cur_class_int = -1\n",
    "                        if \"курганы\" in fname_lower:\n",
    "                            cur_class = \"курганы\"\n",
    "                            cur_class_int = 0\n",
    "                        elif \"дороги\" in fname_lower:\n",
    "                            cur_class = \"дороги\"\n",
    "                            cur_class_int = 1\n",
    "                        elif \"фортификация\" in fname_lower or \"фортификации\" in fname_lower:\n",
    "                            cur_class = \"фортификации\"\n",
    "                            cur_class_int = 2\n",
    "                        elif \"архитектура\" in fname_lower:\n",
    "                            cur_class = \"архитектура\"\n",
    "                            cur_class_int = 3\n",
    "                        elif \"ямы\" in fname_lower:\n",
    "                            cur_class = \"ямы\"\n",
    "                            cur_class_int = 4\n",
    "                        elif \"городище\" in fname_lower or \"городища\" in fname_lower:\n",
    "                            cur_class = \"городище\"\n",
    "                            cur_class_int = 5\n",
    "                        elif \"иное\" in fname_lower:\n",
    "                            cur_class = \"иное\" \n",
    "                            cur_class_int = 6\n",
    "                        elif \"селище\" in fname_lower:\n",
    "                            cur_class = \"селище\" \n",
    "                            cur_class_int = 7\n",
    "                        elif \"пашня\" in fname_lower or \"пахота\" in fname_lower:\n",
    "                            cur_class = \"пашня\" \n",
    "                            cur_class_int = 8\n",
    "                        elif \"межа\" in fname_lower:\n",
    "                            cur_class = \"межа\"\n",
    "                            cur_class_int = 9\n",
    "                        else:\n",
    "                            continue\n",
    "                        try:\n",
    "                            gdf = gpd.read_file(path)\n",
    "                            if gdf.empty:\n",
    "                                continue\n",
    "\n",
    "                            if gdf.crs is None:\n",
    "                                gdf = gdf.set_crs(crs)\n",
    "                            elif gdf.crs != crs:\n",
    "                                gdf1 = gdf.set_crs(src.crs,allow_override=True)\n",
    "                                raster_bounds = src.bounds\n",
    "                                raster_bbox = box(*raster_bounds)\n",
    "                                geojson_bounds = gdf1.total_bounds\n",
    "                                geojson_bbox = box(*geojson_bounds)\n",
    "                                intersection = raster_bbox.intersects(geojson_bbox)\n",
    "                                if intersection:\n",
    "                                    gdf = gdf1\n",
    "                                else:\n",
    "                                    gdf = gdf.to_crs(crs)\n",
    "                            if window_bbox is not None:\n",
    "                                gdf = gdf[gdf.intersects(window_bbox)]\n",
    "                                if gdf.empty:\n",
    "                                    continue\n",
    "                            cur_shape = {\"geom\": [], \"pixel_coords\": [x, y, x_end, y_end], \"class_name\": cur_class, \"class_int\": cur_class_int}\n",
    "                            cur_shape |= images\n",
    "                            for geom in gdf.geometry:\n",
    "                                if geom.is_empty or not geom.is_valid:\n",
    "                                    continue\n",
    "                                if not (geom.intersects(window_bbox)):\n",
    "                                    continue\n",
    "                                if geom.geom_type == \"MultiPolygon\":\n",
    "                                    for geom1 in geom.geoms:\n",
    "                                        cur_shape[\"geom\"].append(mapping(geom1))\n",
    "                                else:\n",
    "                                    cur_shape[\"geom\"].append(mapping(geom))\n",
    "                            if cur_shape[\"geom\"]:\n",
    "                                shapes.append(cur_shape)\n",
    "                                \n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"Ошибка при обработке {path}: {e}\")\n",
    "                            continue\n",
    "with open('thedata.json', 'w') as fp:\n",
    "    json.dump(shapes, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b31626",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d423bd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from rasterio.features import rasterize\n",
    "import random\n",
    "import json\n",
    "from affine import Affine\n",
    "import geopandas\n",
    "from shapely.geometry import Polygon\n",
    "from tools.utils import get_windowss, metrics_ae\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tile_size=2048\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), 1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=1e-4, \n",
    "    total_steps=1000,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "def train_model(model, photo_counter, train_from_scratch=False):\n",
    "    epochal_counter=0\n",
    "    max_iou = 0\n",
    "    random.seed(a=838383)\n",
    "    counter_zero=0\n",
    "    #weights =torch.tensor(CLASS_WEIGHTS)\n",
    "    #weights_reshaped = weights.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "    #print(torch.tensor(CLASS_WEIGHTS).unsqueeze(0).unsqueeze(0).shape)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #weights_final = weights_reshaped.repeat(2, 1, 1, 1).to(device)\n",
    "    criterion = FocalDiceLossBinary()\n",
    "    if train_from_scratch:\n",
    "        checkpoint= torch.load(\".\\\\Segformer_b0_2048_1_.pth\")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        optimizer_to(optimizer,device)\n",
    "        epochal_counter = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        iou = checkpoint['iou']\n",
    "    #ema_model = torch.optim.swa_utils.AveragedModel(model,device,multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(0.9), use_buffers=True)\n",
    "    model.to(device)\n",
    "    image_tensors = []\n",
    "    mask_tensors =[]\n",
    "    train_loss = []\n",
    "    batch_loss = 0.0\n",
    "    counter=0\n",
    "    counter_pashni=0\n",
    "    counter_road=0\n",
    "    with open (\"./thedata.json\",\"r\") as js:\n",
    "        json_data= json.load(js)\n",
    "        for times in range(20):\n",
    "            model.train()\n",
    "            for obj in tqdm(json_data):\n",
    "                running_loss = 0.0\n",
    "                # print(f\"Количество обработанных изображений {photo_counter}\")\n",
    "                photo_counter+=1\n",
    "                yest_curgani = False\n",
    "                for batches in range(len(obj[\"batches\"])):\n",
    "                    res = obj[\"batches\"][batches]\n",
    "                    if obj[\"class_int\"] != 0:\n",
    "                        break\n",
    "                    counter += 1\n",
    "                    update_metadata_only(res[0][0], res[0][0], int(obj[\"UTM\"][0]))\n",
    "                    with rasterio.open(res[0][0]) as src:\n",
    "                        print(res[0])\n",
    "                        window_bounds = obj['pixel_coords']\n",
    "                        window_transform = src.transform * Affine.translation(window_bounds[0], window_bounds[1])\n",
    "                        image = merge_multiband_windowss(res,window_bounds[0],window_bounds[1],tile_size)\n",
    "                        x1 = window_bounds[0]\n",
    "                        x2 = window_bounds[2]\n",
    "                        y1 = window_bounds[1]\n",
    "                        y2 = window_bounds[3]\n",
    "                        if y2<y1 or x2<x1:\n",
    "                            continue\n",
    "                        w, h = x2 - x1, y2 - y1\n",
    "                        print(w,h)\n",
    "                        multimask = np.zeros((1, tile_size, tile_size), dtype=int)\n",
    "                        # print(obj['geom'])\n",
    "                        # print(obj['geom']['coordinates'])\n",
    "                        x1 = []\n",
    "                        for geom in obj[\"geom\"]:\n",
    "                            x1.append(Polygon(geom[\"coordinates\"][0]))\n",
    "                        print(obj[\"UTM\"][0])\n",
    "                        x2 = geopandas.GeoSeries(x1, crs=\"EPSG:\" + str(obj[\"UTM\"][0]))\n",
    "                        multimask[:, 0 : 0 + h, 0 : 0 + w,] = rasterize(\n",
    "                            x2,\n",
    "                            out_shape=(h,w),\n",
    "                            transform=window_transform,\n",
    "                            fill=0,\n",
    "                            dtype=int\n",
    "                        )\n",
    "                        rr = random.randint(0,3)\n",
    "                        multimask  = torch.from_numpy(multimask)\n",
    "                        print(multimask.shape)\n",
    "                        image  = torch.from_numpy(image)\n",
    "                        if rr == 1:\n",
    "                            multimask = torch.rot90(multimask, k=1, dims=[-2, -1])\n",
    "                            image  = torch.rot90(image, k=1, dims=[-2, -1])\n",
    "                        elif rr == 2:\n",
    "                            multimask = torch.rot90(multimask, k=2, dims=[-2, -1])\n",
    "                            image  = torch.rot90(image, k=2, dims=[-2, -1])\n",
    "                        elif rr == 3:\n",
    "                            multimask = torch.rot90(multimask, k=3, dims=[-2, -1])\n",
    "                            image  = torch.rot90(image, k=3, dims=[-2, -1])\n",
    "                        image_tensors.append(image)\n",
    "                        mask_tensors.append(multimask)\n",
    "                        if counter %4 ==0 and counter != 0:\n",
    "                            batch_img = torch.stack(image_tensors, dim=0)\n",
    "                            batch_masks = torch.stack(mask_tensors,dim=0)\n",
    "                            print(batch_masks.shape)\n",
    "                            image_tensors = []\n",
    "                            mask_tensors =[]\n",
    "                            counter_zero=0\n",
    "                            batch_img  = F.interpolate(batch_img, scale_factor=0.25, mode='area')\n",
    "                            batch_masks = F.interpolate(batch_masks.float(), scale_factor=0.25, mode='nearest')\n",
    "                            print(batch_img.shape)\n",
    "                            print(batch_masks.shape)\n",
    "                            batch_img = batch_img.float().to(device) \n",
    "                            batch_masks = batch_masks.to(device)\n",
    "                            optimizer.zero_grad()\n",
    "                            outputs = model(batch_img)\n",
    "                            print(outputs.shape)\n",
    "                            loss = criterion(outputs, batch_masks)  \n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            batch_loss += loss.item()\n",
    "                            running_loss = batch_loss /4\n",
    "                            pred_masks = (torch.sigmoid(outputs)).float()\n",
    "                            with torch.no_grad():\n",
    "                                train_loss.append(loss.cpu().item())\n",
    "                            scheduler.step()\n",
    "                            #ema_model.update_parameters(model)\n",
    "                            iou, prec, rec,f1 = metrics(pred_masks,batch_masks,batch_img,0.5,device)\n",
    "                            batch_loss = 0.0\n",
    "                            counter=0\n",
    "                            print(f'Epoch [{epochal_counter+1}], Loss: {running_loss:.4f},  mean IOU:[{iou}], Precision[{prec:.4f}], Recall [{rec:.4f}], F1_score [{f1:.4f}]')\n",
    "                            epochal_counter +=1\n",
    "                            plot_loss(train_loss)\n",
    "                            print(res[0][0])\n",
    "                            if iou>max_iou:\n",
    "                                torch.cuda.empty_cache()\n",
    "                                torch.save({\n",
    "                                'epoch': epochal_counter,\n",
    "                                'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'loss': loss,\n",
    "                                'iou': iou,\n",
    "                                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                                },  'Segformer_b0_2048_1_li_dem_maxiou.pth')\n",
    "                                max_iou=iou\n",
    "                            torch.save({\n",
    "                            'epoch': epochal_counter,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss': loss,\n",
    "                            'iou': iou,\n",
    "                            'scheduler_state_dict': scheduler.state_dict(),\n",
    "                            },  'Segformer_b0_2048_1_li_dem.pth')\n",
    "                            torch.cuda.empty_cache()\n",
    "    return model\n",
    "\n",
    "    \n",
    "#model = UNet(n_channels=12, n_classes=1)\n",
    "trained_model = train_model(model, 0, train_from_scratch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae58af9-f262-44d3-b660-8f95a3695704",
   "metadata": {},
   "source": [
    "# Обучение (без предварительного вычисления окон, но с аугментациями)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e477e6-d825-4ab7-b433-46af3c2f909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "tile_size=2048\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "#     optimizer,\n",
    "#     max_lr=1e-4, \n",
    "#     total_steps=1000,\n",
    "#     pct_start=0.05,\n",
    "#     anneal_strategy='cos'\n",
    "# )\n",
    "\n",
    "\n",
    "def train_model(model, photo_counter, train_from_scratch=False):\n",
    "    epochal_counter=0\n",
    "    max_iou = 0\n",
    "    random.seed(a=838383)\n",
    "    counter_zero=0\n",
    "    #weights =torch.tensor(CLASS_WEIGHTS)\n",
    "    #weights_reshaped = weights.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
    "    #print(torch.tensor(CLASS_WEIGHTS).unsqueeze(0).unsqueeze(0).shape)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #weights_final = weights_reshaped.repeat(2, 1, 1, 1).to(device)\n",
    "    criterion = FocalDiceLossBinary()\n",
    "\n",
    "    if train_from_scratch:\n",
    "        checkpoint= torch.load(\".\\\\Segformer_b0_2048_1.pth\")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        optimizer_to(optimizer,device)\n",
    "        epochal_counter = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        iou = checkpoint['iou']\n",
    "    # ema_model = torch.optim.swa_utils.AveragedModel(model,device,multi_avg_fn=torch.optim.swa_utils.get_ema_multi_avg_fn(0.9), use_buffers=True)\n",
    "    model.to(device)\n",
    "    image_tensors = []\n",
    "    mask_tensors =[]\n",
    "    train_loss = []\n",
    "    batch_loss = 0.0\n",
    "    counter = 0\n",
    "    dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    for times in range(20):\n",
    "        data_iter = iter(dataloader)\n",
    "        for epoch in range(len(dataloader)):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            images = next(data_iter)\n",
    "            print(f\"Количество обработанных изображений {photo_counter}\")\n",
    "            photo_counter+=1\n",
    "            yest_curgani = False\n",
    "            for batches in range(len(images[\"batches\"])):\n",
    "                res = images[\"batches\"][batches]\n",
    "                for name in images[\"vector_mask\"]:\n",
    "                    print(name)\n",
    "                    if \"курганы\" in name[0]:\n",
    "                        yest_curgani = True\n",
    "                if not yest_curgani:\n",
    "                    print(\"нет_курганов,\",res[0][0])\n",
    "                    break\n",
    "                update_metadata_only(res[0][0], res[0][0], int(images[\"UTM\"][0]))\n",
    "                with rasterio.open(res[0][0]) as src:\n",
    "                    tile_id = 0\n",
    "                    stride = tile_size\n",
    "                    x_range = range(0, src.width + tile_size, stride)\n",
    "                    y_range = range(0, src.height + tile_size, stride)\n",
    "                    factor_stride_x = random.randint(0, tile_size//2)\n",
    "                    factor_stride_y = random.randint(0, tile_size//2)\n",
    "                    for y in tqdm(y_range):\n",
    "                        for x in x_range:\n",
    "                            window_bounds = (x+factor_stride_x, y+factor_stride_y, x+factor_stride_x+ tile_size, y+factor_stride_y + tile_size)\n",
    "                            y_end = min(window_bounds[3], int(src.height))\n",
    "                            x_end = min(window_bounds[2],  int(src.width))\n",
    "                            if (x + factor_stride_x < x_end and y + factor_stride_y < y_end):\n",
    "                                image = merge_multiband_windowss(res,x+factor_stride_x,y+factor_stride_y,tile_size)\n",
    "                                multimask = multigeojson_to_multichannel_mask(images[\"vector_mask\"],src, window_bounds)[0]\n",
    "                                if  len(np.nonzero(multimask[0])[0])<100:\n",
    "                                    if counter_zero>=1:\n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        counter_zero+=1\n",
    "\n",
    "                                counter += 1\n",
    "                                rr = random.randint(0,3)\n",
    "                                multimask  = torch.from_numpy(multimask)\n",
    "                                image  = torch.from_numpy(image)\n",
    "                                if rr == 1:\n",
    "                                    multimask = torch.rot90(multimask, k=1, dims=[-2, -1])\n",
    "                                    image  = torch.rot90(image, k=1, dims=[-2, -1])\n",
    "                                elif rr == 2:\n",
    "                                    multimask = torch.rot90(multimask, k=2, dims=[-2, -1])\n",
    "                                    image  = torch.rot90(image, k=2, dims=[-2, -1])\n",
    "                                elif rr == 3:\n",
    "                                    multimask = torch.rot90(multimask, k=3, dims=[-2, -1])\n",
    "                                    image  = torch.rot90(image, k=3, dims=[-2, -1])\n",
    "                                image_tensors.append(image)\n",
    "                                mask_tensors.append(multimask)\n",
    "                                if counter % 4 == 0 and counter != 0:\n",
    "                                    batch_img = torch.stack(image_tensors, dim=0)\n",
    "                                    batch_masks = torch.stack(mask_tensors,dim=0)\n",
    "                                    batch_masks = batch_masks.unsqueeze(0)\n",
    "                                    batch_masks = torch.permute(batch_masks,(1,0,2,3))\n",
    "                                    image_tensors = []\n",
    "                                    mask_tensors =[]\n",
    "                                    counter_zero=0\n",
    "                                    batch_img  = F.interpolate(batch_img, scale_factor=0.25, mode='area')\n",
    "                                    batch_masks = F.interpolate(batch_masks.float(), scale_factor=0.25, mode='nearest')\n",
    "                                    print(batch_img.shape)\n",
    "                                    print(batch_masks.shape)\n",
    "                                    batch_img = batch_img.float().to(device) \n",
    "                                    batch_masks = batch_masks.to(device)\n",
    "                                    for sub_ep in range(50):\n",
    "                                        outputs = model(batch_img)\n",
    "                                        print(outputs.shape)\n",
    "                                        loss = criterion(outputs, batch_masks)  \n",
    "                                        optimizer.zero_grad()\n",
    "                                        loss.backward()\n",
    "                                        optimizer.step()\n",
    "                                        batch_loss = loss.item()\n",
    "                                        running_loss = batch_loss /4\n",
    "                                        pred_masks = (torch.sigmoid(outputs)).float()\n",
    "                                        with torch.no_grad():\n",
    "                                            train_loss.append(batch_loss)\n",
    "                                        # scheduler.step()\n",
    "                                        # ema_model.update_parameters(model)\n",
    "                                        iou, prec, rec,f1 = metrics(pred_masks,batch_masks,batch_img,0.5,device)\n",
    "                                        counter = 0\n",
    "                                        if sub_ep % 10 == 0:\n",
    "                                            print(f'Epoch [{epochal_counter+1}], Loss: {batch_loss:.4f},  mean IOU:[{iou}], Precision[{prec:.4f}], Recall [{rec:.4f}], F1_score [{f1:.4f}]')\n",
    "                                            epochal_counter +=1 \n",
    "                                            plot_loss(train_loss)\n",
    "                                            print(res[0][0])\n",
    "                                        batch_loss = 0.0\n",
    "                                        if iou > max_iou:\n",
    "                                            torch.cuda.empty_cache()\n",
    "                                            torch.save({\n",
    "                                            'epoch': epochal_counter,\n",
    "                                            'model_state_dict': model.state_dict(),\n",
    "                                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                            'loss': loss,\n",
    "                                            'iou': iou,\n",
    "                                                },  'Segformer_b0_2048_11_maxiou.pth')\n",
    "                                            max_iou = iou\n",
    "                                        torch.save({\n",
    "                                        'epoch': epochal_counter,\n",
    "                                        'model_state_dict': model.state_dict(),\n",
    "                                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                        'loss': loss,\n",
    "                                        'iou': iou,\n",
    "                                            },  'Segformer_b0_2048_11.pth')\n",
    "                                        torch.cuda.empty_cache()\n",
    "    return model\n",
    "\n",
    "#model = UNet(n_channels=12, n_classes=1)\n",
    "trained_model = train_model(model, 0, train_from_scratch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1934b67-3b9f-4f63-868f-f6b33c4d2655",
   "metadata": {},
   "source": [
    "# Обучение Классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61cb8ad7-ba77-419a-9009-701e1cd3d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.utils import metrics_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb00fd5c-2d92-4229-a015-5b7b2cf658b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.Mob_net_classificator import MobileNetV3Small\n",
    "model = MobileNetV3Small(num_classes=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3966583-f87c-43e9-86b9-46697afcb8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tile_size=2048\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "def train_det_model(model, photo_counter, train_from_scratch=False):\n",
    "    train_loss = []\n",
    "    epochal_counter = 0\n",
    "    max_f1 = 0\n",
    "    random.seed(a=838383)\n",
    "    counter_zero=0\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-6)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "    if train_from_scratch:\n",
    "        checkpoint = torch.load(\".\\\\Mob_net_class_.pth\")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        optimizer_to(optimizer,device)\n",
    "        epochal_counter = checkpoint['epoch']\n",
    "        loss = checkpoint['loss']\n",
    "        f1 = checkpoint['f1']\n",
    "        prec = checkpoint['prec']\n",
    "        rec = checkpoint['rec']\n",
    "    model.to(device)\n",
    "    image_tensors = []\n",
    "    logits_tensors =[]\n",
    "    batch_loss = 0.0\n",
    "    counter = 0\n",
    "    counter_road =0\n",
    "    dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    for times in range(20):\n",
    "        data_iter = iter(dataloader)\n",
    "        for epoch in range(len(dataloader)):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            single_image_batch = next(data_iter)\n",
    "            images = single_image_batch\n",
    "            print(f\"Количество обработанных изображений {photo_counter}\")\n",
    "            photo_counter+=1\n",
    "            yest_curgani = False\n",
    "            for batches in range(len(images[\"batches\"])):\n",
    "                res = images[\"batches\"][batches]\n",
    "                update_metadata_only(res[0][0], res[0][0], int(images[\"UTM\"][0]))\n",
    "                with rasterio.open(res[0][0]) as src:\n",
    "                    tile_id = 0\n",
    "                    stride = tile_size\n",
    "                    x_range = range(0, src.width + tile_size, stride)\n",
    "                    y_range = range(0, src.height + tile_size, stride)\n",
    "                    factor_stride_x = random.randint(0, tile_size)\n",
    "                    factor_stride_y = random.randint(0, tile_size)\n",
    "                    for y in tqdm(y_range):\n",
    "                        for x in x_range:\n",
    "                            window_bounds = (x+factor_stride_x, y+factor_stride_y, x+factor_stride_x+ tile_size, y+factor_stride_y + tile_size)\n",
    "                            y_end = min(window_bounds[3], int(src.height))\n",
    "                            x_end = min(window_bounds[2],  int(src.width))\n",
    "                            if (x + factor_stride_x < x_end and y + factor_stride_y < y_end):\n",
    "                                image = merge_multiband_windowss(res,x+factor_stride_x,y+factor_stride_y,tile_size)\n",
    "                                multimask = multigeojson_to_multichannel_mask(images[\"vector_mask\"],src, window_bounds)\n",
    "                                if  len(np.nonzero(multimask[0])[0])>100:\n",
    "                                    class_ = 1\n",
    "                                elif len(np.nonzero(multimask[1])[0])>100:\n",
    "                                    if counter_road<3:\n",
    "                                        class_ = 2\n",
    "                                        counter_road+=1\n",
    "                                    else:\n",
    "                                         continue\n",
    "                                elif len(np.nonzero(multimask[2])[0])>100:\n",
    "                                    class_ = 3\n",
    "                                elif len(np.nonzero(multimask[3])[0])>100:\n",
    "                                    class_ = 4\n",
    "                                elif len(np.nonzero(multimask[4])[0])>100:\n",
    "                                    class_ = 5\n",
    "                                elif len(np.nonzero(multimask[5])[0])>100:\n",
    "                                    class_ = 6\n",
    "                                elif len(np.nonzero(multimask[6])[0])>100:\n",
    "                                    class_ = 7\n",
    "                                elif len(np.nonzero(multimask[7])[0])>100:\n",
    "                                    class_ = 8\n",
    "                                elif len(np.nonzero(multimask[8])[0])>100:\n",
    "                                    class_ = 9\n",
    "                                elif len(np.nonzero(multimask[9])[0])>100:\n",
    "                                    class_ = 10\n",
    "                                else:\n",
    "                                    if counter_zero<6:\n",
    "                                        counter_zero += 1\n",
    "                                        class_ = 0\n",
    "                                    else:\n",
    "                                        continue\n",
    "                                #one_hot_class = F.one_hot(torch.tensor(class_), num_classes = 11).float()\n",
    "                                counter+=1\n",
    "                                rr = random.randint(0,3)\n",
    "                                image  = torch.from_numpy(image)\n",
    "                                if rr == 1:\n",
    "                                    image  = torch.rot90(image, k=1, dims=[-2, -1])\n",
    "                                elif rr == 2:\n",
    "                                    image  = torch.rot90(image, k=2, dims=[-2, -1])\n",
    "                                elif rr == 3:\n",
    "                                    image  = torch.rot90(image, k=3, dims=[-2, -1])\n",
    "                                image_tensors.append(image)\n",
    "                                logits_tensors.append(class_)\n",
    "                                if counter %16 ==0 and counter != 0:\n",
    "                                    batch_img = torch.stack(image_tensors, dim=0)\n",
    "                                    batch_masks = torch.tensor(logits_tensors)\n",
    "                                    image_tensors = []\n",
    "                                    logits_tensors =[]\n",
    "                                    counter_zero=0\n",
    "                                    batch_img  = F.interpolate(batch_img, scale_factor=0.25, mode='area')\n",
    "                                    print(batch_img.shape)\n",
    "                                    print(batch_masks.shape)\n",
    "                                    batch_img = batch_img.float().to(device) \n",
    "                                    batch_masks = batch_masks.to(device)\n",
    "                                    outputs = model(batch_img)\n",
    "                                    print(outputs.shape)\n",
    "                                    loss = criterion(outputs, batch_masks)\n",
    "                                    optimizer.zero_grad()\n",
    "                                    loss.backward()\n",
    "                                    optimizer.step()\n",
    "                                    batch_loss += loss.item()\n",
    "                                    running_loss = batch_loss /16\n",
    "                                    with torch.no_grad():\n",
    "                                        train_loss.append(loss.cpu().item())\n",
    "                                    prec, rec,f1 = metrics_det(outputs,batch_masks,batch_img, device)\n",
    "                                    batch_loss = 0.0\n",
    "                                    counter = 0\n",
    "                                    counter_road = 0\n",
    "                                    if  epochal_counter!=0 and epochal_counter%10==0:\n",
    "                                        plot_loss(train_loss)\n",
    "                                    print(f'Epoch [{epochal_counter+1}], Loss: {running_loss:.4f}, Precision[{prec:.4f}], Recall [{rec:.4f}], F1_score [{f1:.4f}]')\n",
    "                                    epochal_counter +=1\n",
    "                                    if f1>max_f1:\n",
    "                                        torch.cuda.empty_cache()\n",
    "                                        torch.save({\n",
    "                                        'epoch': epochal_counter,\n",
    "                                        'model_state_dict': model.state_dict(),\n",
    "                                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                        'loss': loss,\n",
    "                                        'f1':f1,\n",
    "                                        'prec':prec,\n",
    "                                        'rec':rec\n",
    "                                          },  'Mob_net_class_maxf1.pth')\n",
    "                                        max_f1=f1\n",
    "                                    torch.save({\n",
    "                                        'epoch': epochal_counter,\n",
    "                                        'model_state_dict': model.state_dict(),\n",
    "                                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                        'loss': loss,\n",
    "                                        'f1':f1,\n",
    "                                        'prec':prec,\n",
    "                                        'rec':rec\n",
    "                                          },  'Mob_net_class_.pth')\n",
    "                                    torch.cuda.empty_cache()\n",
    "    return model\n",
    "\n",
    "trained_model = train_det_model(model, 0, train_from_scratch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb9f31-ec35-49db-bf73-3c69badd4fe0",
   "metadata": {},
   "source": [
    "# Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3faf689-c8a9-456b-95c3-000839beb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.Mob_net_classificator import MobileNetV3Small\n",
    "vis_model = MobileNetV3Small(num_classes=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbd762-0c34-4088-91e0-17d8779d9e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import shapely\n",
    "from shapely.geometry import MultiPolygon, Polygon, mapping, shape\n",
    "from tools.test_module import mask_to_polygons, apply_transforms\n",
    "from tools.utils import metrics_test\n",
    "import json\n",
    "\n",
    "tile_size = 2048\n",
    "# трансформ из окна в изображение\n",
    "# трансформ изображения в координаты\n",
    "# трансформ из коорд в epsg:3587\n",
    "\n",
    "def test_model(model, photo_counter):\n",
    "    feature_cnt = 0\n",
    "    result = {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "    max_iou = 0\n",
    "    checkpoint= torch.load(\"Segformer_b0_2048_1_kurg.pth\", map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    loss = checkpoint['loss']\n",
    "    iou = checkpoint['iou']\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   \n",
    "    model.to(device)\n",
    "    checkpoint2 =torch.load(\"Mob_net_class_.pth\", map_location='cpu')\n",
    "    vis_model.load_state_dict(checkpoint2['model_state_dict'])\n",
    "    vis_model.to(device)\n",
    "    counter=0\n",
    "    epochal_counter = 0\n",
    "    dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    data_iter = iter(dataloader)\n",
    "    to_compare = {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "    for epoch in range(len(dataloader)):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.eval()\n",
    "        #vis_model.eval()\n",
    "        single_image_batch = next(data_iter)\n",
    "        images = single_image_batch\n",
    "        cur_flag = True\n",
    "        polygons = []\n",
    "        for batches in range(len(images[\"batches\"])):\n",
    "            res = images[\"batches\"][batches]\n",
    "            update_metadata_only(res[0][0], res[0][0], int(images[\"UTM\"][0]))  \n",
    "            with rasterio.open(res[0][0]) as src:\n",
    "                if not cur_flag:\n",
    "                    break\n",
    "                cur_flag = False\n",
    "                for name in images[\"vector_mask\"]:\n",
    "                    if \"курганы\" in name[0]:\n",
    "                        cur_flag=name[0]\n",
    "                if not cur_flag:\n",
    "                    print(\"нет_курганы,\",res[0][0])\n",
    "                    break\n",
    "                counter = 0\n",
    "                photo_counter+=1\n",
    "                print(f\"Количество обработанных изображений {photo_counter}\")\n",
    "                tile_id = 0\n",
    "                stride = tile_size//2\n",
    "                x_range = range(0, src.width + tile_size, stride)\n",
    "                y_range = range(0, src.height + tile_size, stride)\n",
    "                for y in tqdm(y_range):\n",
    "                    for x in x_range:\n",
    "                        window_bounds = (x, y, x + tile_size, y + tile_size)\n",
    "                        y_end = min(window_bounds[3], int(src.height))\n",
    "                        x_end = min(window_bounds[2],  int(src.width))\n",
    "                        if (x<x_end and y<y_end):\n",
    "                            image = merge_multiband_windowss(res,x,y,tile_size)\n",
    "                            multimask = multigeojson_to_multichannel_mask(images[\"vector_mask\"],src, window_bounds)[0]\n",
    "                            multi = multimask\n",
    "                            multimask  = torch.from_numpy(multimask)\n",
    "                            image  = torch.from_numpy(image)\n",
    "                            image  =  image.unsqueeze(0)\n",
    "                            image = F.interpolate(image , scale_factor=0.25, mode='area')\n",
    "                            multimask  = multimask.unsqueeze(0)\n",
    "                            multimask = multimask.unsqueeze(0)\n",
    "                            multimask =F.interpolate(multimask.float(), scale_factor=0.25, mode='nearest').int()\n",
    "                            print(image.shape)\n",
    "                            print(multimask.shape)\n",
    "                            image = image.float().to(device)\n",
    "                            #eye =  torch.softmax(vis_model(image),dim =1)\n",
    "                            #print(eye[0][1])\n",
    "                            #if eye[0][1]<0.05:\n",
    "                                #continue\n",
    "                            threshhold = 0.7\n",
    "                            outputs = model(image)\n",
    "                            multimask = multimask.to(device)\n",
    "                            outputs = torch.sigmoid(outputs)\n",
    "                            iou, prec, rec,f1 = metrics_test(outputs,multimask,image, threshhold,device)\n",
    "                            outputs = F.interpolate(outputs, scale_factor=4, mode='nearest')\n",
    "                            counter+=1\n",
    "                            epochal_counter +=1\n",
    "                            outputs = outputs.detach().cpu().numpy()\n",
    "                            for polygon in mask_to_polygons(outputs[0][0], x,y, threshhold):#МОЖЕТ СЛОМАТЬСЯ ИЗ_ЗА ФОРМАТА РАСТЕРИО ХРАНЕНИЯ ИЗОБРАЖЕНИЙ (h,w)):\n",
    "                                polygon = apply_transforms(polygon, \"EPSG:\"+ images[\"UTM\"][0],src.transform)\n",
    "                                polygons.append(polygon)\n",
    "                            torch.cuda.empty_cache()\n",
    "        mask_names = [\"kurgany\",\"dorogi\",\"fortifikatsii\",\"arkhitektury\",\"yamy\",\"gorodishche\",\"inoe\",\"selishcha\",\"pashni\",\"mezha\"]\n",
    "        if cur_flag is not False:\n",
    "            # curflag = разметка текущая\n",
    "            polygons = list(shapely.union_all(polygons).normalize().geoms)\n",
    "            print(f'Image [{res[0][0]}]')\n",
    "            feature_reg_name = images[\"region_name\"][0]\n",
    "            feature_subreg_name = \"\" if images[\"region_name\"][0] == images[\"sub_region_name\"][0] else images[\"sub_region_name\"][0]\n",
    "            feature_subreg_name = feature_subreg_name\n",
    "            # классы внутри цикла по классам\n",
    "            feature_markup_type = images[\"markup_type\"][0]\n",
    "            feature_original_crs = \"urn:ogc:def:crs:EPSG::\" + images[\"UTM\"][0]\n",
    "            feature_crs = \"urn:ogc:def:crs:EPSG::3857\"\n",
    "# ---------- преобразование их разметки в формат нужный\n",
    "            feature_class_name = \"kurgany\" #КУРГАНЫ ONLY\n",
    "            with open(cur_flag) as fff:\n",
    "                d = json.load(fff)\n",
    "                feature_cnt = 0\n",
    "                for feature in d[\"features\"]:\n",
    "                    for polyg_raw in list(feature[\"geometry\"][\"coordinates\"]):\n",
    "                        polyg = None\n",
    "                        if \"ЛИХУША\" in feature_reg_name:\n",
    "                            polyg = polyg_raw[0]\n",
    "                        else:\n",
    "                            polyg = polyg_raw\n",
    "                        polyg_tuple = (tuple(x) for x in polyg)\n",
    "                        polyg_sh = Polygon(polyg_tuple)\n",
    "                        cur_feature = {}\n",
    "                        cur_feature[\"type\"] = \"Feature\"\n",
    "                        cur_feature[\"properties\"] = {\n",
    "                            \"class_name\": feature_class_name,\n",
    "                            \"region_name\": feature_reg_name,\n",
    "                            \"sub_region_name\": feature_subreg_name,\n",
    "                            \"markup_type\": feature_markup_type,\n",
    "                            \"original_crs\": feature_original_crs,\n",
    "                            \"crs\": feature_crs,\n",
    "                            \"fid\": feature_cnt\n",
    "                        }\n",
    "                        feature_cnt += 1\n",
    "                        cur_feature[\"geometry\"] =  mapping(polyg_sh)\n",
    "                        to_compare[\"features\"].append(cur_feature)\n",
    "            # ----------- результат модели записываем\n",
    "            feature_cnt = 0\n",
    "            for class_idx in range(1):\n",
    "                for polygon in polygons:\n",
    "                    feature_class_name = mask_names[class_idx]\n",
    "                    feature = {}\n",
    "                    feature[\"type\"] = \"Feature\"\n",
    "                    feature[\"properties\"] = {\n",
    "                        \"class_name\": feature_class_name,\n",
    "                        \"region_name\": feature_reg_name,\n",
    "                        \"sub_region_name\": feature_subreg_name,\n",
    "                        \"markup_type\": feature_markup_type,\n",
    "                        \"original_crs\": feature_original_crs,\n",
    "                        \"crs\": feature_crs,\n",
    "                        \"fid\": feature_cnt\n",
    "                    }\n",
    "                    feature_cnt += 1\n",
    "                    feature[\"geometry\"] =  mapping(polygon)\n",
    "                    \n",
    "                    result[\"features\"].append(feature)\n",
    "            output_file =\".\\\\result1.geojson\"\n",
    "            with open(output_file,\"w\", encoding=\"utf-8\") as handle:\n",
    "                json.dump(result, handle, ensure_ascii=False, indent=2)\n",
    "            with open(\"to_compare.geojson\",\"w\", encoding=\"utf-8\") as handle:\n",
    "                json.dump(to_compare, handle, ensure_ascii=False, indent=2)\n",
    "            %run ./tools/compute_metrics_qual.py --predictions result1.geojson  --ground-truth to_compare.geojson\n",
    "\n",
    "test_model(model, 0)                                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
